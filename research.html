<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="stylesheet.css">
</head>

<div id="navbar">
<h4> <a href="index.html"> Ethan Gotlieb Wilcox </a> • <a href="research.html"> Research</a> • <a href="teaching.html"> Teaching</a> • <a href="errata.html"> Miscellany </a> <br> <hr> </h4> 
</div>

<b> Computational Models of Hard-To-Learn Syntactic Phenomena </b> <br> <br>

<img style="float:left; padding-right: 6px;" src="images/islands.png" alt="lang_impact" height="110">

How do humans learn syntactic structures? Is the computational mechanism bounded by innate constraints, perhaps even language-specific ones? To what extent must one be engaged in communication, as opposed to say just pattern recognition, in order to learn syntax? This work seeks to understand what syntactic structures can be learned by domain-general learning algorithms trained to predict the next word given a context. The primary focus of the work is on models' ability to learn <i> filler--gap dependencies </i> and the related constraints on them, including island constraints. The papers listed below follow a sequential order, so start from the top and read down if you're interested. 

<br>
<br>

<u>Publications</u><br>
<a href="https://arxiv.org/pdf/1809.00042.pdf">[•]</a> Wilcox, Ethan; Levy, Roger; Morita, Takashi; Futrell, Richard. 2018. What do RNN Language Models Learn about the Filler-Gap Dependency? <i> Proceedings of Blackbox NLP at EMNLP 2018 </i> <br>
<a href="https://arxiv.org/pdf/1903.00943.pdf">[•]</a> Ethan Wilcox, Peng Qian, Richard Futrell, Miguel Ballesteros, Roger Levy. 2019. Structural Supervision Improves Learning for Non-Local Dependencies. <i> NAACL-HLT 2019 </i> <br>
<a href="https://arxiv.org/pdf/1905.10431.pdf"> [•] </a> Ethan Wilcox Roger Levy and Richard Futrell. 2019. ​What Syntactic Structures block Dependencies in RNN Language Models? ​<i> Proceedings of CogSci 2019. </i> <br>
<a href="https://arxiv.org/pdf/1906.04068.pdf"> [•] </a> Ethan Wilcox, ​Roger Levy and Richard Futrell. 2019. ​Hierarchical Representation in Neural Language Models: Suppression and Recovery of Expectations. ​<i> Proceedings of Blackbox NLP at ACL 2019 </i> Forthcoming <br>
<br>

<b> Neural Networks as Models of Human Language Processing </b> <br> <br>

<img style="float:left; padding-right: 6px;" src="images/human_rnn.png" alt="lang_impact" height="110">

Neural networks are everywhere, and have achieved state of the art performance on many NLP tasks. But to what extent do they serve as good models for human linguistic processing? This work seeks to benchmark neural network models by treating them like subjects in a psycholinguistic experiment. By deriving word-by-word predictions, and comparing these to classic studies of human word-by-word reading times, we can uncover the ways in which models' learned representations are driving behavior that is similar to (and different from) human behavior. <br><br>

<u>Publications/Presentations</u><br>
<a href="images/CUNY2020_Poster.pdf">[•]</a> Ethan Wilcox, Jon Gauthier, Peng Qian, Jennifer Hu and Roger Levy. 2020. Evaluating the Effect of Model Inductive Bias and Training Data in Predicting Human Reading Times. <i> CUNY Conference on Sentence Processing. (Poster) </i> <br>
<a href="https://arxiv.org/pdf/1909.04625.pdf"> [•]</a> Aixiu An, Peng Qian, Ethan Wilcox, and Roger Levy. 2019. Representation of Constituents in Neural Language Models: Coordination Phrase as a Case Study. <i> EMNLP 2019 </i> <br>
<a href="https://www.aclweb.org/anthology/N19-1004">[•]</a> Richard Futrell, Ethan Wilcox, Takashi Morita, Miguel Ballesteros, Roger Levy. 2019. Neural Language Models as Psycholinguistic Subjects: Representation of Syntactic State. <i> NAACL-HLT 2019 </i> <br>
<a href="https://arxiv.org/pdf/1809.00042.pdf">[•]</a> Futrell, Richard; Wilcox, Ethan; Morita, Takashi; Levy, Roger. 2018. RNNs as Psycholinguistic Subjects: Grammatical State and Syntactic Dependency <br> <br>

<b> Recursive Models of Pragmatics </b> <br> <br>

The interpretation of linguistics utterances in context depends on the prior beliefs of speakers and hearers. At the same time listeners often make pragmatic inferences. When these two things --- prior beliefs and pragmatic inferences -- are pitted against each other, what happens? In this work we test human subjects on <i> exhaustivity effects </i> and seek to model their responses using a recursive, Bayesian model of pragmatics (the Rational Speech Act model).

<br>
<br>

<u> Publications </u> <br>
<a href="https://mindmodeling.org/cogsci2019/papers/0519/0519.pdf"> [•] </a> Ethan Wilcox​ and Benjamin Spector. 2019. ​The Role of Prior Beliefs in The Rational Speech Act Model of Pragmatics: Exhaustivity as a Case Study​. <i> Proceedings of CogSci 2019 </i> <br> <br>

<b> Models of Language Change and Language Loss </b> <br> <br>

<img style="float:left; padding-right: 6px;" src="images/lang_impact.png" alt="lang_impact" height="100">

The past 100 years have produced massive changes in the way humans live, travel, produce goods and organize societies. The next 100 years will see even more change, from the increasing urbanization of the planet, to the continued processes of decolonization and industrialization, to the impact of climate change. The effects these ongoing changes have on the world's linguistic diversity are poorly understood. I am using global census data from the late 20th century to understand what factors have lead to language change in the past, with the hope of building interpretable predictive models. <br><br>

<u> Presentations </u> <br>
<a href="images/Climate_Hotspots_Language.pdf">[•]</a> Ethan Wilcox. 2019. Using Global Hotspots to assess the Effects of Climate Change on Linguistic Diversity. Computational Psycholinguistics Lab Meeting, MIT.


