Authors,URL,Title,Publication,Year
"Brandon Waldon, Nathan Schneider, \textbf{Ethan Gotlieb Wilcox}, Amir Zeldes, Kevin Tobia",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5123124,Large Language Models for Legal Interpretation? {D}on’t Take Their Word for It,Georgetown Law Journal,2025
"Anna A. Ivanova, Aalok Sathe, Benjamin Lipkin, Unnathi Kumar, Setayesh Radkani, Thomas H. Clark, Carina Kauf, Jennifer Hu, R. T. Pramod, Gabriel Grand, Vivian Paulun, Maria Ryskina, Ekin Akyürek, \textbf{Ethan Gotlieb Wilcox}, Nafisa Rashid, Leshem Choshen, Roger Levy, Evelina Fedorenko, Joshua Tenenbaum, Jacob Andreas",https://arxiv.org/pdf/2405.09605,Elements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic world knowledge in language models,"Under Review, Transactions of the Association for Computational Linguistics",2025
"\textbf{Ethan Gotlieb Wilcox}, Michael Y. Hu, Alex Warstadt, Aaron Mueller, Leshem Choshen, Chengxu Zhuang, Adina Williams, Ryan Cotterell, Tal Linzen",https://osf.io/preprints/psyarxiv/rfwgd,Bigger is not always better: {T}he importance of human-scale language modeling for psycholinguistics,"under review, Journal of Memory and Language",2025
"John Mansfield, \textbf{Ethan Gotlieb Wilcox}",,Looking Forward: Linguistic Theory and Methods,"Under Review, Oxford University Press",2025
"\textbf{Ethan Gotlieb Wilcox}, Cui Ding, Mrinmaya Sachan, Lena Jäger","https://www.sciencedirect.com/science/article/pii/S0749596X24000378#:~:text=We%20introduce%20Mouse%20Tracking%20for,the%20tip%20of%20the%20mouse.",Mouse Tracking while Reading (MoTR): A New Incremental Processing Measurement,Journal of Memory and Language,2024
"\textbf{Ethan Gotlieb Wilcox}, Tiago Pimentel, Clara Meister, Ryan Cotterell",https://www.sciencedirect.com/science/article/pii/S0010027724000519,An Information-Theoretic Analysis of Targeted Regressions During Reading,Cognition,2024
"Michael Hu, Aaron Mueller, Candace Ross, Adina Williams, Tal Linzen, Chengxu Zhuang, Ryan Cotterell, Leshem Choshen, Alex Warstadt, \textbf{Ethan Gotlieb Wilcox}",https://arxiv.org/abs/2412.05149,Findings of the Second BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora,Proceedings of the 2024 BabyLM Challenge,2024
"Eleftheria Tsipidi, Franz Nowak, Ryan Cotterell, \textbf{Ethan Gotlieb Wilcox}, Mario Giulianelli, Alex Warstadt",https://aclanthology.org/2024.emnlp-main.1047/,Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse,Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP),2024
"Samuel Kiegeland*, \textbf{Ethan Gotlieb Wilcox}*, Afra Amini, David Robert Reich, Ryan Cotterell",https://aclanthology.org/2024.emnlp-main.526/,Reverse Engineering the Reader,Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP),2024
"Andreas Opedal, Eleanor Chodroff, Ryan Cotterell, \textbf{Ethan Gotlieb Wilcox}",https://aclanthology.org/2024.emnlp-main.179/,On the Role of Context in Reading Time Prediction,Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP),2024
"Samuel Kiegeland, David Robert Reich, Ryan Cotterell, Lena Ann Jäger, \textbf{Ethan Gotlieb Wilcox}",https://openreview.net/pdf?id=8oLUcBgKua,The Pupil Becomes the Master,Proceedings of the 2024 ICML Workshop on LLMs and Cognition,2024
"\textbf{Ethan Gotlieb Wilcox}, Tiago Pimentel, Clara Meister, Ryan Cotterell, Roger Levy",https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00612/118718/Testing-the-Predictions-of-Surprisal-Theory-in-11,Testing the Predictions of Surprisal Theory in 11 Languages,Transactions of the Association for Computational Linguistics,2023
"Alexandre Cremers, \textbf{Ethan Gotlieb Wilcox}, Benjamin Spector",https://onlinelibrary.wiley.com/doi/full/10.1111/cogs.13286,Exhaustivity and Anti-Exhaustivity in the RSA Framework: Testing the Effect of Prior Beliefs,Cognitive Science,2023
"Tiago Pimentel, Clara Miester, \textbf{Ethan Gotlieb Wilcox}, Roger Levy and Ryan Cotterell",https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00603/118720/On-the-Effect-of-Anticipation-on-Reading-Times,On the Effect of Anticipation on Reading Times,Transactions of the Association for Computational Linguistics,2023
"\textbf{Ethan Gotlieb Wilcox}, Richard Futrell and Roger Levy",https://direct.mit.edu/ling/article-abstract/doi/10.1162/ling_a_00491/113304/Using-Computational-Models-to-Test-Syntactic,Using Computational Models to Test Syntactic Learnability,Linguistic Inquiry,2023
"\textbf{Ethan Gotlieb Wilcox}, Clara Meister, Ryan Cotterell, Tiago Pimentel",https://aclanthology.org/2023.emnlp-main.466/,Language Model Quality Correlates with Psychometric Predictive Power in Multiple Languages,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP),2023
"Tiago Pimentel, Clara Meister, \textbf{Ethan Gotlieb Wilcox}, Ryan Cotterell, Kyle Mahowald",https://aclanthology.org/2023.emnlp-main.137/,Revisiting the Optimality of Word Lengths,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP),2023
"Lukas Wolf, Tiago Pimentel, Evelina Fedorenko, Ryan Cotterell, Alex Warstadt, \textbf{Ethan Gotlieb Wilcox}, Tamar Regev",https://aclanthology.org/2023.emnlp-main.606/,Quantifying the redundancy between prosody and text,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP),2023
"Lukas Wolf, Klemen Kotar, Greta Tuckute, Eghbal Hosseini, Alex Warstadt, \textbf{Ethan Gotlieb Wilcox}, Tamar Regev",https://aclanthology.org/2023.conll-babylm.21/,WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words,Proceedings of the 2023 BabyLM Challenge,2023
"Alex Warstadt, Aaron Mueller, Leshem Choshen, \textbf{Ethan Gotlieb Wilcox}, Chengxu Zhuang, Juan Ciro, Rafael Mosquera, Adina Williams, Bhargavi Paranjabe, Tal Linzen, Ryan Cotterell",https://aclanthology.org/2023.conll-babylm.1/,Findings of the BabyLM Challenge: Sample-efficient Pretraining on Developmentally Plausible Corpora,Proceedings of the 2023 BabyLM Challenge,2023
"Clara Meister, Tiago Pimentel, Luca Malagutti, \textbf{Ethan Gotlieb Wilcox}, Ryan Cotterell",https://aclanthology.org/2023.acl-long.80,On the Efficacy of Sampling Adapters,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),2023
"Wangchunshu Zhou, Yuchen Jiang, \textbf{Ethan Gotlieb Wilcox}, Ryan Cotterell, Mrinmaya Sachan",https://aclanthology.org/2023.acl-long.80,Controlled Text Generation with Natural Language Instructions,Proceedings of the International Conference on Machine Learning (ICML),2023
"Thomas Clark, \textbf{Ethan Gotlieb Wilcox}, Edward Gibson, Roger Levy",https://escholarship.org/uc/item/1q19f8vt,Which Evidence for Availability Effects on Speaker Choice in the Russian Comparative Alternation,Proceedings of the Annual Meeting of the Cognitive Science Society,2022
"\textbf{Ethan Gotlieb Wilcox}, Jon Gauthier, Peng Qian, Jennifer Hu and Roger Levy",https://www.taylorfrancis.com/chapters/edit/10.1201/9781003205388-6/learning-syntactic-structures-string-input-ethan-gotlieb-wilcox-jon-gauthier-jennifer-hu-peng-qian-roger-levy,Learning Syntactic Structures from String Input,"Algebraic Structures in Natural Language, CRC Press, pp. 113-138 2022",2022
"\textbf{Ethan Gotlieb Wilcox}, Roger Levy, Kathryn Davidson",https://lingbuzz.net/lingbuzz/007677?_s=JDfmZuvHzO745LFc&_k=-DTEP54v36rFIE1I,Presupposing Novel Information: A Cross-Trigger Experiment in English,LingBuzz Preprint,2022
"\textbf{Ethan Gotlieb Wilcox}, Roger Levy, Kathryn Davidson",https://journals.linguisticsociety.org/proceedings/index.php/SALT/article/view/31.018/4819,Which Presuppositions are Subject to Contextual Felicity Constraints?,Proceedings of the Semantics and Linguistic Theory (SALT),2021
"\textbf{Ethan Gotlieb Wilcox}, Pranali Vani, Roger Levy",https://aclanthology.org/2021.acl-long.76,A Targeted Assessment of Incremental Processing in Neural Language Models and Humans,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),2021
"Pranali Vani, \textbf{Ethan Gotlieb Wilcox}, Roger Levy",https://escholarship.org/uc/item/3x34x7dz,Using the interpolated maze task to assess incremental processing in English relative clauses,Proceedings of the Annual Meeting of the Cognitive Science Society,2021
"\textbf{Ethan Gotlieb Wilcox}, Jon Gauthier, Jennifer Hu, Peng Qian, Roger Levy",https://cogsci.mindmodeling.org/2020/papers/0375/index.html,On the Predictive Power of Neural Language Models for Human Real-Time Comprehension Behavior,Proceedings of the Annual Meeting of the Cognitive Science Society,2020
"\textbf{Ethan Gotlieb Wilcox}, Peng Qian, Richard Futrell, Ryosuke Kohita, Roger Levy, Miguel Ballesteros",https://aclanthology.org/2020.emnlp-main.375,Structural Supervision Improves Few-Shot Learning and Syntactic Generalization in Neural Language Models,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),2020
"Tristan Thrush, \textbf{Ethan Gotlieb Wilcox}, Roger Levy",https://aclanthology.org/2020.blackboxnlp-1.25,Investigating Novel Verb Learning in {BERT}: Selectional Preference Classes and Alternation-Based Syntactic Generalization,Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP,2020
"Jennifer Hu, Peng Qian, Jon Gauther, \textbf{Ethan Gotlieb Wilcox}, Roger Levy",https://aclanthology.org/2020.acl-main.158,A Systematic Assessment of Syntactic Generalization in Neural Language Models,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,2020
"Jon Gauther, Jennifer Hu, \textbf{Ethan Gotlieb Wilcox}, Peng Qian, Roger Levy",https://aclanthology.org/2020.acl-demos.10,{S}yntax{G}ym: An Online Platform for Targeted Evaluation of Language Models,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,2020
"\textbf{Ethan Gotlieb Wilcox}, Roger Levy, Richard Futrell",https://cogsci.mindmodeling.org/2019/papers/0219/0219.pdf,What syntactic structures block dependencies in RNN language models?,Proceedings of the Annual Meeting of the Cognitive Science Society,2019
"Richard Futrell, \textbf{Ethan Gotlieb Wilcox}, Takashi Morita, Peng Qian, Miguel Ballesteros, Roger Levy",https://aclanthology.org/N19-1004,Neural language models as psycholinguistic subjects: Representations of syntactic state,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",2019
"\textbf{Ethan Gotlieb Wilcox}, Peng Qian, Richard Futrell, Miguel Ballesteros, Roger Levy",https://aclanthology.org/N19-1334,Structural Supervision Improves Learning of Non-Local Grammatical Dependencies,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",2019
"Aixiu An, Peng Qian, \textbf{Ethan Gotlieb Wilcox}, Roger Levy",https://aclanthology.org/D19-1287,Representation of Constituents in Neural Language Models: Coordination Phrase as a Case Study,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),2019
"\textbf{Ethan Gotlieb Wilcox}, Roger Levy, Richard Futrell",https://aclanthology.org/W19-4819,Hierarchical Representation in Neural Language Models: Suppression and Recovery of Expectations,Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP,2019
"\textbf{Ethan Gotlieb Wilcox}, Benjamin Spector",https://cogsci.mindmodeling.org/2019/papers/0519/0519.pdf,The Role of Prior Beliefs in The Rational Speech Act Model of Pragmatics: Exhaustivity as a Case Study,Proceedings of the Annual Meeting of the Cognitive Science Society,2019
"\textbf{Ethan Gotlieb Wilcox}, Roger Levy, Takashi Morita, Richard Futrell",https://aclanthology.org/W18-5423,What do {RNN} Language Models Learn about Filler{--}Gap Dependencies?,Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP},2018